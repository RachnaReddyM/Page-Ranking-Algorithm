The below are required to compile and run the DFS_crawler.py program:

1. Python 2.7.14
2. requests library which can be installed using the command:
   pip install requests
3. Beautiful Soup4 library to pull data out of HTML and XML. It can be installed using the command:
   pip install beautifulsoup4

------------------------------------------------------------------------------------------------------------------------
To compile and run the programs:

1. Open Command Prompt and move to the directory in which the .py files are placed.
2. Enter the following command:
   python PageRank.py
   python DFS_crawler.py

--------------------------------------------------------------------------------------------------------------------------

NOTE:

This code has used "math" and "operator" libraries which are in-built in any python compiler. If not, please install it.

--------------------------------------------------------------------------------------------------------------------------
   
This folder contains the following files:

1. Task 1 A - G1.txt * Graph of URLs generated through BFS*
2. Task 1 B - G2.txt * Graph of URLs generated through DFS*
3. Task 1   - Task1Report.txt *Statistics of G1 and G2*
4. Task 1 B - DFS_crawler.py  * Source code of DFS crawler *
4. Task 2   - PageRank.py * Page Rank source code*
5. Task 2   - PerplexityG1, PerplexityG2 * Lists the Perplexity values of each round until convergence *
6. Task 2   - PageRankG1, PageRankG2     * Sorted Page Ranks of the top 50 pages for G1 and G2 *
7. Task 3   - Task3Report.txt            * Comparison and speculation about Page Rank values *


-----------------------------------------------------------------------------------------------------------------------------

Citations:
1. Python- http://www.pythonforbeginners.com/python-on-the-web/web-scraping-with-beautifulsoup/
2. Python- https://docs.python.org/3/
3. Stack Overflow - to fix few errors faced during working with dictionaries in python

------------------------------------------------------------------------------------------------------------------------------